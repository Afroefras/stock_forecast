{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Corner/Catalog/Stock_fcst/data'\n",
    "BRANCH_ID = 9988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     0.667215\n",
      "1     0.070872\n",
      "9     0.050511\n",
      "4     0.040288\n",
      "2     0.039854\n",
      "8     0.032230\n",
      "0     0.025212\n",
      "10    0.024866\n",
      "6     0.018801\n",
      "5     0.016202\n",
      "7     0.013949\n",
      "Name: family_one, dtype: float64 \n",
      "\n",
      "\n",
      "2.0     0.471062\n",
      "NaN     0.332785\n",
      "7.0     0.034396\n",
      "0.0     0.025559\n",
      "9.0     0.023220\n",
      "6.0     0.022267\n",
      "4.0     0.020707\n",
      "3.0     0.017328\n",
      "10.0    0.015335\n",
      "8.0     0.015075\n",
      "1.0     0.013343\n",
      "5.0     0.008924\n",
      "Name: family_two, dtype: float64 \n",
      "\n",
      "\n",
      "NaN     0.528938\n",
      "2.0     0.276988\n",
      "9.0     0.035609\n",
      "4.0     0.027465\n",
      "0.0     0.022180\n",
      "8.0     0.021920\n",
      "6.0     0.019754\n",
      "5.0     0.018801\n",
      "3.0     0.014556\n",
      "10.0    0.012736\n",
      "1.0     0.011350\n",
      "7.0     0.009704\n",
      "Name: family_three, dtype: float64 \n",
      "\n",
      "\n",
      "Archivo: 9988_fam.csv fue exportado exitosamente en:\n",
      "/Users/efraflores/Desktop/EF/Corner/Catalog/Stock_fcst/data\n"
     ]
    }
   ],
   "source": [
    "# Control de datos\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from pickle import dump as save_pkl\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# Ingeniería de variables\n",
    "from re import sub, UNICODE\n",
    "from numpy import nan, array\n",
    "from datetime import datetime\n",
    "from unicodedata import normalize\n",
    "from nltk.corpus import stopwords\n",
    "from string import ascii_uppercase\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "# Modelos\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "class StockForecast:\n",
    "    def __init__(self, base_dir: str, branch_id: int) -> None:\n",
    "        '''\n",
    "        Obtener un directorio como texto y convertirlo a tipo Path para unir directorios, buscar archivos, etc.\n",
    "        '''\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.branch_id = branch_id\n",
    "        self.file_name = f'{self.branch_id}_op.csv'\n",
    "\n",
    "        # Definir la ruta completa para leer el archivo\n",
    "        self.file_path = self.base_dir.joinpath(self.file_name)\n",
    "\n",
    "        # Verificar que existe el archivo en el directorio\n",
    "        if not self.file_path.is_file():\n",
    "            print(f'Debería haber un archivo llamado: \"{self.file_name}\" en el directorio:\\n{self.base_dir}\\n\\nAgrégalo e intenta de nuevo!\\n')\n",
    "\n",
    "    def export_csv(self, df: DataFrame, name_suffix=None, **kwargs) -> None: \n",
    "        '''\n",
    "        Exportar un archivo en formato csv\n",
    "        '''\n",
    "        export_name = f'{self.branch_id}.csv' if name_suffix==None else f'{self.branch_id}_{name_suffix}.csv'\n",
    "        df.to_csv(self.base_dir.joinpath(export_name), **kwargs)\n",
    "        print(f'Archivo: {export_name} fue exportado exitosamente en:\\n{self.base_dir}')\n",
    "\n",
    "    def get_file(self, testing: bool=True, id_col: str='product_id', cols: list=['product','category','brand']) -> DataFrame:\n",
    "        '''\n",
    "        Importar el csv a nivel orden-producto y construir la tabla de productos\n",
    "        '''\n",
    "        if testing:\n",
    "            # Leer sólo una fracción del archivo para confirmar que el flujo corre sin problemas\n",
    "            chunks = read_csv(self.file_path, chunksize=1000)\n",
    "            df = DataFrame()\n",
    "            for i,chunk in enumerate(chunks):\n",
    "                # Solamente se usará el primer chunk de 1K renglones\n",
    "                if i > 0: break\n",
    "                else: df = df.append(chunk)\n",
    "            self.df = df\n",
    "\n",
    "        else: self.df = read_csv(self.file_path)\n",
    "        \n",
    "        # Una tabla con los productos, para crear las familias en un método posterior\n",
    "        self.prod = self.df.drop_duplicates(id_col).set_index(id_col)[cols]\n",
    "\n",
    "    def clean_text(self, text: str, pattern: str=\"[^a-zA-Z0-9\\s]\", lower: bool=True, rem_stopw: bool=False, stopwords_list: list=[]) -> str: \n",
    "        '''\n",
    "        Limpieza de texto\n",
    "        '''\n",
    "        # Reemplazar acentos: áàäâã --> a\n",
    "        clean = normalize('NFD', str(text).replace('\\n', ' \\n ')).encode('ascii', 'ignore')\n",
    "        # Omitir caracteres especiales !\"#$%&/()=...\n",
    "        clean = sub(pattern, ' ', clean.decode('utf-8'), flags=UNICODE)\n",
    "        # Mantener sólo un espacio\n",
    "        clean = sub(r'\\s{2,}', ' ', clean.strip())\n",
    "        # Minúsculas si el parámetro lo indica\n",
    "        if lower: clean = clean.lower()\n",
    "        if rem_stopw: clean = ' '.join(filter(lambda x: x not in stopwords_list, clean.split()))\n",
    "        # Si el registro estaba vacío, indicar nulo\n",
    "        if clean in ('','nan'): clean = nan\n",
    "        return clean\n",
    "\n",
    "    def create_families(self, n_families: int=11, export_result: bool=False, **kwargs) -> None:\n",
    "\n",
    "        X = self.prod.apply(lambda x: self.clean_text(''.join(str(x)), rem_stopw=True, stopwords_list=stopwords.words('spanish')+sf.prod.columns.tolist()+['nan']), axis=1)\n",
    "        \n",
    "        family_model_one = Pipeline(steps=[('countv', CountVectorizer(**kwargs)),('cluster',KMeans(n_families, random_state=22))])\n",
    "        self.prod['family_one'] = family_model_one.fit_predict(X)\n",
    "        top_fam_one = self.prod['family_one'].value_counts(1, dropna=False)\n",
    "        print(top_fam_one,'\\n'*2)\n",
    "\n",
    "        X = X.to_frame().rename({0:'text'}, axis=1)\n",
    "        X['family_one'] = self.prod['family_one']\n",
    "\n",
    "        X_sub = X[X['family_one']==top_fam_one.index[0]].copy()\n",
    "\n",
    "        family_model_two = Pipeline(steps=[('countv', CountVectorizer(**kwargs)),('cluster',KMeans(n_families, random_state=22))])\n",
    "        X_sub['family_two'] = family_model_two.fit_predict(X_sub['text'])\n",
    "        self.prod = self.prod.join(X_sub[['family_two']])\n",
    "\n",
    "        top_fam_two = self.prod['family_two'].value_counts(1, dropna=False)\n",
    "        print(top_fam_two,'\\n'*2)\n",
    "\n",
    "        X['family_two'] = self.prod['family_two']\n",
    "        X_sub_sub = X[X['family_two']==top_fam_two.index[0]].copy()\n",
    "\n",
    "        family_model_three = Pipeline(steps=[('countv', CountVectorizer(**kwargs)),('cluster',KMeans(n_families, random_state=22))])\n",
    "        X_sub_sub['family_three'] = family_model_three.fit_predict(X_sub_sub['text'])\n",
    "        self.prod = self.prod.join(X_sub_sub[['family_three']])\n",
    "\n",
    "        top_fam_three = self.prod['family_three'].value_counts(1, dropna=False)\n",
    "        print(top_fam_three,'\\n'*2)\n",
    "        \n",
    "        if export_result: self.export_csv(self.prod, name_suffix='fam')\n",
    "\n",
    "sf = StockForecast(BASE_DIR, BRANCH_ID)\n",
    "sf.get_file(testing=False)\n",
    "sf.create_families(max_features=10000, export_result=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a926e39c7f6b4e2762c697714a7e0aa72a30532c94f3d2e2ab9584caaf509beb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('stock_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
